#!/usr/bin/env bash
# run_pipeline.sh - å¿«é€Ÿè¿è¡Œ answer â†’ evaluate å®Œæ•´æµç¨‹
#
# ç”¨æ³•:
#   ./run_pipeline.sh                    # ä½¿ç”¨é»˜è®¤æ¨¡å‹ gpt-5.1
#   ./run_pipeline.sh gpt-4o             # æŒ‡å®šæ¨¡å‹
#   ./run_pipeline.sh gpt-5.1 20         # æŒ‡å®šæ¨¡å‹å’Œæ•°é‡é™åˆ¶
#   ./run_pipeline.sh gpt-5.1 20 8       # æŒ‡å®šæ¨¡å‹ã€æ•°é‡å’Œå¹¶å‘æ•°

set -e

MODEL="${1:-gpt-5.1}"
LIMIT="${2:-91}"
WORKERS="${3:-8}"
DATA_DIR="yaml_blocks"
BASE_URL="https://api.openai.com/"

echo "==================================="
echo "ğŸš€ Pipeline: ${MODEL}"
echo "   Data: ${DATA_DIR}"
echo "   Limit: ${LIMIT}"
echo "   Workers: ${WORKERS}"
echo "==================================="

# Step 1: Generate Answers
echo ""
echo "ğŸ“ Step 1: Generating Answers..."
uv run python main.py answer \
--out-dir "${DATA_DIR}" \
--model "${MODEL}" \
--base-url "${BASE_URL}" \
--workers "${WORKERS}" \
--limit "${LIMIT}" \
--force

# Step 2: Evaluate Answers
echo ""
echo "ğŸ” Step 2: Evaluating Answers..."
uv run python main.py evaluate \
--input-dir "${DATA_DIR}" \
--model "${MODEL}" \
--base-url "${BASE_URL}" \
--workers "${WORKERS}" \
--limit "${LIMIT}" \
--force

echo ""
echo "==================================="
echo "âœ… Pipeline Complete!"
echo "   Results: ${DATA_DIR}/results.csv"
echo "==================================="
